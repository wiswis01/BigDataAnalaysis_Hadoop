#!/bin/bash
# -*- coding: utf-8 -*-
# run.sh - Pipeline MapReduce pour Cluster Hadoop Docker
# Version corrig√©e et optimis√©e

set -e  # Arr√™ter en cas d'erreur

# ============================================================================
# CONFIGURATION
# ============================================================================

PROJECT_DIR="/root/project"
DATA_DIR="$PROJECT_DIR/data"
SRC_DIR="$PROJECT_DIR/src"
LOCAL_OUTPUT="$PROJECT_DIR/output"
HDFS_INPUT="/user/root/project/input"
HDFS_OUTPUT="/user/root/project/output"

# Couleurs
RED='\033[0;31m'
GREEN='\033[0;32m'
YELLOW='\033[1;33m'
BLUE='\033[0;34m'
CYAN='\033[0;36m'
NC='\033[0m'

# ============================================================================
# FONCTIONS UTILITAIRES
# ============================================================================

print_step() {
    echo -e "${BLUE}==>${NC} ${GREEN}$1${NC}"
}

print_substep() {
    echo -e "  ${CYAN}‚Üí${NC} $1"
}

print_warning() {
    echo -e "${YELLOW}‚ö†Ô∏è  $1${NC}"
}

print_error() {
    echo -e "${RED}‚ùå $1${NC}"
}

print_success() {
    echo -e "${GREEN}‚úì $1${NC}"
}

check_prerequisites() {
    print_step "V√©rification des pr√©requis dans le cluster Docker..."
    
    # V√©rifier Hadoop
    if ! command -v hadoop &> /dev/null; then
        print_error "Hadoop n'est pas install√©"
        exit 1
    fi
    
    # V√©rifier HDFS
    if ! hdfs dfs -ls / &> /dev/null; then
        print_error "HDFS ne r√©pond pas. V√©rifiez: jps"
        exit 1
    fi
    
    # V√©rifier Python
    if ! command -v python3 &> /dev/null; then
        print_error "Python 3 n'est pas install√©"
        exit 1
    fi
    
    # V√©rifier mrjob
    if ! python3 -c "import mrjob" 2>/dev/null; then
        print_warning "mrjob n'est pas install√©. Installation en cours..."
        pip3 install mrjob -q
        if ! python3 -c "import mrjob" 2>/dev/null; then
            print_error "Impossible d'installer mrjob"
            exit 1
        fi
    fi
    
    # V√©rifier les datanodes
    DATANODES=$(hdfs dfsadmin -report 2>/dev/null | grep "Live datanodes" | grep -oP '\d+' || echo "0")
    if [ "$DATANODES" -lt 2 ]; then
        print_warning "Seulement $DATANODES datanode(s) actif(s). Attendu: 2"
    else
        print_success "Cluster OK: $DATANODES datanodes actifs"
    fi
    
    # V√©rifier les fichiers source Python
    REQUIRED_SCRIPTS=("
    _valider.py" "analyse_ventes.py" "top_produits.py")
    for script in "${REQUIRED_SCRIPTS[@]}"; do
        if [ ! -f "$SRC_DIR/$script" ]; then
            print_error "Script manquant: $SRC_DIR/$script"
            exit 1
        fi
    done
    
    print_success "Tous les pr√©requis sont satisfaits"
}

check_hdfs_data() {
    print_step "V√©rification des donn√©es dans HDFS..."
    
    # V√©rifier les fichiers locaux
    REQUIRED_FILES=("ventes_multicanal.csv" "ventes_increment_2025-10.csv" "catalogue_produits.csv")
    missing=0
    
    for f in "${REQUIRED_FILES[@]}"; do
        if [ ! -f "$DATA_DIR/$f" ]; then
            print_error "Fichier manquant: $DATA_DIR/$f"
            missing=1
        else
            size=$(du -h "$DATA_DIR/$f" | cut -f1)
            print_substep "Trouv√©: $f ($size)"
        fi
    done
    
    if [ "$missing" -eq 1 ]; then
        print_error "Des fichiers sont manquants. Pipeline interrompu."
        exit 1
    fi
    
    # Cr√©er les r√©pertoires HDFS si n√©cessaire
    hdfs dfs -mkdir -p "$HDFS_INPUT" 2>/dev/null || true
    
    # Charger les donn√©es dans HDFS (avec v√©rification)
    print_substep "Chargement des donn√©es dans HDFS..."
    
    for f in "${REQUIRED_FILES[@]}"; do
        # Supprimer l'ancien fichier s'il existe
        hdfs dfs -rm -f "$HDFS_INPUT/$f" 2>/dev/null || true
        
        # Copier le nouveau fichier
        if hdfs dfs -put "$DATA_DIR/$f" "$HDFS_INPUT/" 2>/dev/null; then
            print_substep "‚úì $f charg√© dans HDFS"
        else
            print_error "√âchec du chargement de $f"
            exit 1
        fi
    done
    
    print_success "Donn√©es charg√©es dans HDFS avec succ√®s"
}

clean_output() {
    print_step "Nettoyage des sorties pr√©c√©dentes..."
    
    # Nettoyer HDFS (supprimer seulement les sous-dossiers)
    for dir in clean rejects metrics top10; do
        hdfs dfs -rm -r -f -skipTrash "$HDFS_OUTPUT/$dir" 2>/dev/null || true
        hdfs dfs -mkdir -p "$HDFS_OUTPUT/$dir" 2>/dev/null || true
    done
    
    # Nettoyer local
    rm -rf "$LOCAL_OUTPUT"/* 2>/dev/null || true
    mkdir -p "$LOCAL_OUTPUT"/{clean,rejects,metrics,top10,logs}
    
    print_success "Nettoyage effectu√©"
}

# ============================================================================
# √âTAPE 1: NETTOYAGE DES DONN√âES
# ============================================================================

run_data_cleaning() {
    print_step "√âTAPE 1/3: Nettoyage des donn√©es avec MapReduce..."
    
    cd "$SRC_DIR"
    
    # Traitement v1
    print_substep "Traitement ventes_multicanal.csv (sch√©ma v1)..."
    
    if python3 nettoyer_valider.py \
        -r hadoop \
        --hadoop-streaming-jar $(ls /usr/local/hadoop/share/hadoop/tools/lib/hadoop-streaming-3.3.6.jar | head -1) \
        --schema-version=v1 \
        --output-dir="$HDFS_OUTPUT/clean/v1" \
        "$HDFS_INPUT/ventes_multicanal.csv" \
        > "$LOCAL_OUTPUT/logs/cleaning_v1.log" 2>&1; then
        print_substep "‚úì v1 termin√©"
    else
        print_error "√âchec du nettoyage v1. Voir: $LOCAL_OUTPUT/logs/cleaning_v1.log"
        cat "$LOCAL_OUTPUT/logs/cleaning_v1.log" | tail -20
        exit 1
    fi
    
    # Traitement v2
    print_substep "Traitement ventes_increment_2025-10.csv (sch√©ma v2)..."
    
    if python3 nettoyer_valider.py \
        -r hadoop \
        --hadoop-streaming-jar $(ls /usr/local/hadoop/share/hadoop/tools/lib/hadoop-streaming-3.3.6.jar| head -1) \
        --schema-version=v2 \
        --output-dir="$HDFS_OUTPUT/clean/v2" \
        "$HDFS_INPUT/ventes_increment_2025-10.csv" \
        > "$LOCAL_OUTPUT/logs/cleaning_v2.log" 2>&1; then
        print_substep "‚úì v2 termin√©"
    else
        print_error "√âchec du nettoyage v2. Voir: $LOCAL_OUTPUT/logs/cleaning_v2.log"
        cat "$LOCAL_OUTPUT/logs/cleaning_v2.log" | tail -20
        exit 1
    fi
    
    # Combiner les r√©sultats
    print_substep "Combinaison des fichiers nettoy√©s..."
    
    # V√©rifier que les fichiers existent avant de les combiner
    if ! hdfs dfs -test -e "$HDFS_OUTPUT/clean/v1/part-00000" 2>/dev/null; then
        print_error "Aucune sortie g√©n√©r√©e pour v1"
        exit 1
    fi
    
    # Combiner les r√©sultats
    hdfs dfs -cat "$HDFS_OUTPUT/clean/v1/part-*" "$HDFS_OUTPUT/clean/v2/part-*" 2>/dev/null \
        | hdfs dfs -put -f - "$HDFS_OUTPUT/clean/combined.txt"
    
    # S√©parer CLEAN et REJECT
    print_substep "S√©paration des enregistrements valides et rejet√©s..."
    
    # Cr√©er clean_only.txt (sans les lignes REJECT)
    hdfs dfs -cat "$HDFS_OUTPUT/clean/combined.txt" 2>/dev/null \
        | awk -F'\t' '$1 !~ /REJECT/' \
        | hdfs dfs -put -f - "$HDFS_OUTPUT/clean/clean_only.txt"
    
    # Cr√©er rejected_lines.txt (seulement les lignes REJECT)
    hdfs dfs -cat "$HDFS_OUTPUT/clean/combined.txt" 2>/dev/null \
        | awk -F'\t' '$1 ~ /REJECT/' \
        | hdfs dfs -put -f - "$HDFS_OUTPUT/rejects/rejected_lines.txt" || true
    
    # Statistiques
    echo ""
    print_substep "üìä Statistiques de nettoyage:"
    
    TOTAL=$(hdfs dfs -cat "$HDFS_OUTPUT/clean/combined.txt" 2>/dev/null | wc -l || echo 0)
    CLEAN=$(hdfs dfs -cat "$HDFS_OUTPUT/clean/clean_only.txt" 2>/dev/null | wc -l || echo 0)
    REJECT=$(hdfs dfs -cat "$HDFS_OUTPUT/rejects/rejected_lines.txt" 2>/dev/null | wc -l || echo 0)
    
    echo "    Total lignes trait√©es: $TOTAL"
    echo "    Lignes valides: $CLEAN ($(awk -v c=$CLEAN -v t=$TOTAL 'BEGIN{printf "%.1f", (c/t)*100}')%)"
    echo "    Lignes rejet√©es: $REJECT ($(awk -v r=$REJECT -v t=$TOTAL 'BEGIN{printf "%.1f", (r/t)*100}')%)"
    
    # Extraire quelques exemples de rejets
    if [ "$REJECT" -gt 0 ]; then
        echo ""
        print_substep "Exemples d'erreurs d√©tect√©es:"
        hdfs dfs -cat "$HDFS_OUTPUT/rejects/rejected_lines.txt" 2>/dev/null | head -3 | cut -f1-2 | sed 's/^/      /'
    fi
    
    print_success "Nettoyage termin√©"
}

# ============================================================================
# √âTAPE 2: ANALYSE DES VENTES (KPIs)
# ============================================================================

run_sales_analysis() {
    print_step "√âTAPE 2/3: Calcul des KPIs avec MapReduce..."
    
    cd "$SRC_DIR"
    
    # V√©rifier que des donn√©es nettoy√©es existent
    if ! hdfs dfs -test -e "$HDFS_OUTPUT/clean/clean_only.txt" 2>/dev/null; then
        print_error "Aucune donn√©e nettoy√©e disponible pour l'analyse"
        exit 1
    fi
    
    CLEAN_COUNT=$(hdfs dfs -cat "$HDFS_OUTPUT/clean/clean_only.txt" 2>/dev/null | wc -l || echo 0)
    if [ "$CLEAN_COUNT" -eq 0 ]; then
        print_error "Le fichier clean_only.txt est vide"
        exit 1
    fi
    
    print_substep "Calcul des ventes par pays/mois et taux de retour..."
    print_substep "Traitement de $CLEAN_COUNT enregistrements..."
    
    if python3 analyse_ventes.py \
        -r hadoop \
        --hadoop-streaming-jar $(ls /usr/local/hadoop/share/hadoop/tools/lib/hadoop-streaming-3.3.6.jar | head -1) \
        --output-dir="$HDFS_OUTPUT/metrics" \
        "$HDFS_OUTPUT/clean/clean_only.txt" \
        > "$LOCAL_OUTPUT/logs/analysis.log" 2>&1; then
        print_substep "‚úì Analyse termin√©e"
    else
        print_error "√âchec de l'analyse. Voir: $LOCAL_OUTPUT/logs/analysis.log"
        cat "$LOCAL_OUTPUT/logs/analysis.log" | tail -20
        exit 1
    fi
    
    # Extraire les r√©sultats
    print_substep "Extraction des r√©sultats depuis HDFS..."
    
    # Cr√©er les r√©pertoires locaux
    mkdir -p "$LOCAL_OUTPUT/metrics"
    
    # R√©cup√©rer les r√©sultats
    if hdfs dfs -test -e "$HDFS_OUTPUT/metrics/part-00000" 2>/dev/null; then
        hdfs dfs -get "$HDFS_OUTPUT/metrics/part-*" "$LOCAL_OUTPUT/metrics/" 2>/dev/null || true
        
        # S√©parer SALES et METRICS
        if [ -f "$LOCAL_OUTPUT/metrics/part-00000" ]; then
            cat "$LOCAL_OUTPUT/metrics/part-"* 2>/dev/null \
                | awk -F'\t' '$1 ~ /SALES/ {print $2}' \
                > "$LOCAL_OUTPUT/metrics/sales_by_country_month.jsonl"
            
            cat "$LOCAL_OUTPUT/metrics/part-"* 2>/dev/null \
                | awk -F'\t' '$1 ~ /METRICS/ {print $2}' \
                > "$LOCAL_OUTPUT/metrics/return_rate.jsonl"
            
            # Afficher un aper√ßu
            SALES_COUNT=$(wc -l < "$LOCAL_OUTPUT/metrics/sales_by_country_month.jsonl" 2>/dev/null || echo 0)
            print_substep "‚úì $SALES_COUNT agr√©gations pays/mois g√©n√©r√©es"
            
            if [ -s "$LOCAL_OUTPUT/metrics/return_rate.jsonl" ]; then
                RETURN_RATE=$(cat "$LOCAL_OUTPUT/metrics/return_rate.jsonl" | python3 -c "import sys, json; d=json.load(sys.stdin); print(d.get('return_rate_by_qty', 0))" 2>/dev/null || echo "N/A")
                print_substep "‚úì Taux de retour calcul√©: $RETURN_RATE%"
            fi
        fi
    else
        print_warning "Aucun r√©sultat trouv√© dans HDFS"
    fi
    
    print_success "Analyse des ventes termin√©e"
}

# ============================================================================
# √âTAPE 3: TOP 10 PRODUITS
# ============================================================================

run_top_products() {
    print_step "√âTAPE 3/3: Calcul du Top 10 produits avec MapReduce..."
    
    cd "$SRC_DIR"
    
    print_substep "Analyse des produits les plus vendus..."
    
    if python3 top_produits.py \
        -r hadoop \
        --hadoop-streaming-jar $(ls /usr/local/hadoop/share/hadoop/tools/lib/hadoop-streaming-3.3.6.jar | head -1) \
        --file="$DATA_DIR/catalogue_produits.csv" \
        --output-dir="$HDFS_OUTPUT/top10" \
        "$HDFS_OUTPUT/clean/clean_only.txt" \
        > "$LOCAL_OUTPUT/logs/top10.log" 2>&1; then
        print_substep "‚úì Calcul termin√©"
    else
        print_error "√âchec du calcul du top 10. Voir: $LOCAL_OUTPUT/logs/top10.log"
        cat "$LOCAL_OUTPUT/logs/top10.log" | tail -20
        exit 1
    fi
    
    # Extraire les r√©sultats
    print_substep "Extraction des r√©sultats..."
    
    mkdir -p "$LOCAL_OUTPUT/top10"
    
    if hdfs dfs -test -e "$HDFS_OUTPUT/top10/part-00000" 2>/dev/null; then
        hdfs dfs -get "$HDFS_OUTPUT/top10/part-*" "$LOCAL_OUTPUT/top10/" 2>/dev/null || true
        
        # Combiner et formater
        cat "$LOCAL_OUTPUT/top10/part-"* 2>/dev/null \
            | sort \
            > "$LOCAL_OUTPUT/top10/top10_products.txt"
        
        # Afficher un aper√ßu
        if [ -s "$LOCAL_OUTPUT/top10/top10_products.txt" ]; then
            echo ""
            print_substep "üèÜ Aper√ßu du Top 3:"
            head -3 "$LOCAL_OUTPUT/top10/top10_products.txt" | while read line; do
                echo "      $(echo "$line" | cut -f2)"
            done
        fi
    else
        print_warning "Aucun r√©sultat trouv√©"
    fi
    
    print_success "Top 10 calcul√©"
}

# ============================================================================
# G√âN√âRATION DU RAPPORT
# ============================================================================

generate_report() {
    print_step "G√©n√©ration du rapport de synth√®se..."
    
    REPORT_FILE="$LOCAL_OUTPUT/RAPPORT_EXECUTION.txt"
    
    cat > "$REPORT_FILE" << EOF
================================================================================
                    RAPPORT D'EX√âCUTION
           ANALYSE DE VENTES MULTICANAL - MAPREDUCE
================================================================================

Date d'ex√©cution : $(date '+%Y-%m-%d %H:%M:%S')
Hostname         : $(hostname)
R√©pertoire projet: $PROJECT_DIR
Version Hadoop   : $(hadoop version | head -1)

================================================================================
1. CONFIGURATION DU CLUSTER
================================================================================

NameNode         : hadoop_master
DataNodes        : worker-1, worker-2
R√©plication HDFS : $(hdfs getconf -confKey dfs.replication 2>/dev/null || echo "N/A")

√âtat du cluster:
EOF
    
    hdfs dfsadmin -report 2>&1 | head -15 >> "$REPORT_FILE"
    
    cat >> "$REPORT_FILE" << EOF

Utilisation HDFS pour ce projet:
EOF
    
    hdfs dfs -du -h /user/root/project/ 2>&1 >> "$REPORT_FILE"
    
    cat >> "$REPORT_FILE" << EOF

================================================================================
2. STATISTIQUES DE NETTOYAGE DES DONN√âES
================================================================================

EOF
    
    # Calculer les statistiques
    TOTAL=$(hdfs dfs -cat "$HDFS_OUTPUT/clean/combined.txt" 2>/dev/null | wc -l || echo 0)
    CLEAN=$(hdfs dfs -cat "$HDFS_OUTPUT/clean/clean_only.txt" 2>/dev/null | wc -l || echo 0)
    REJECT=$(hdfs dfs -cat "$HDFS_OUTPUT/rejects/rejected_lines.txt" 2>/dev/null | wc -l || echo 0)
    
    SUCCESS_RATE="0.00"
    if [ "$TOTAL" -gt 0 ]; then
        SUCCESS_RATE=$(awk -v c="$CLEAN" -v t="$TOTAL" 'BEGIN{printf "%.2f", (c/t)*100}')
    fi
    
    cat >> "$REPORT_FILE" << EOF
Total de lignes trait√©es    : $TOTAL
Lignes valides (CLEAN)      : $CLEAN
Lignes rejet√©es (REJECT)    : $REJECT
Taux de r√©ussite            : $SUCCESS_RATE%

Fichiers trait√©s:
  - ventes_multicanal.csv (sch√©ma v1)
  - ventes_increment_2025-10.csv (sch√©ma v2)

Logs d√©taill√©s:
  - Nettoyage v1: $LOCAL_OUTPUT/logs/cleaning_v1.log
  - Nettoyage v2: $LOCAL_OUTPUT/logs/cleaning_v2.log

Exemples d'erreurs d√©tect√©es:
EOF
    
    if [ "$REJECT" -gt 0 ]; then
        hdfs dfs -cat "$HDFS_OUTPUT/rejects/rejected_lines.txt" 2>/dev/null | head -5 | cut -f1-2 | sed 's/^/  /' >> "$REPORT_FILE"
    else
        echo "  Aucune erreur d√©tect√©e" >> "$REPORT_FILE"
    fi
    
    cat >> "$REPORT_FILE" << EOF

================================================================================
3. INDICATEURS DE VENTES (KPIs)
================================================================================

EOF
    
    # Taux de retour
    if [ -f "$LOCAL_OUTPUT/metrics/return_rate.jsonl" ] && [ -s "$LOCAL_OUTPUT/metrics/return_rate.jsonl" ]; then
        echo "3.1 TAUX DE RETOUR GLOBAL" >> "$REPORT_FILE"
        echo "" >> "$REPORT_FILE"
        cat "$LOCAL_OUTPUT/metrics/return_rate.jsonl" 2>/dev/null | python3 -m json.tool >> "$REPORT_FILE" 2>/dev/null || echo "Erreur de formatage" >> "$REPORT_FILE"
    else
        echo "‚ö†Ô∏è  Taux de retour non disponible" >> "$REPORT_FILE"
    fi
    
    echo "" >> "$REPORT_FILE"
    echo "3.2 VENTES PAR PAYS ET MOIS" >> "$REPORT_FILE"
    echo "" >> "$REPORT_FILE"
    
    if [ -f "$LOCAL_OUTPUT/metrics/sales_by_country_month.jsonl" ] && [ -s "$LOCAL_OUTPUT/metrics/sales_by_country_month.jsonl" ]; then
        SALES_COUNT=$(wc -l < "$LOCAL_OUTPUT/metrics/sales_by_country_month.jsonl")
        echo "Nombre d'agr√©gations: $SALES_COUNT" >> "$REPORT_FILE"
        echo "" >> "$REPORT_FILE"
        echo "Exemples (5 premi√®res lignes):" >> "$REPORT_FILE"
        head -5 "$LOCAL_OUTPUT/metrics/sales_by_country_month.jsonl" 2>/dev/null | python3 -m json.tool >> "$REPORT_FILE" 2>/dev/null || echo "Erreur de formatage" >> "$REPORT_FILE"
    else
        echo "‚ö†Ô∏è  Donn√©es de ventes non disponibles" >> "$REPORT_FILE"
    fi
    
    cat >> "$REPORT_FILE" << EOF

Fichier complet: $LOCAL_OUTPUT/metrics/sales_by_country_month.jsonl

================================================================================
4. TOP 10 DES PRODUITS PAR CHIFFRE D'AFFAIRES
================================================================================

EOF
    
    if [ -f "$LOCAL_OUTPUT/top10/top10_products.txt" ] && [ -s "$LOCAL_OUTPUT/top10/top10_products.txt" ]; then
        echo "Classement des 10 meilleurs produits:" >> "$REPORT_FILE"
        echo "" >> "$REPORT_FILE"
        cat "$LOCAL_OUTPUT/top10/top10_products.txt" 2>/dev/null | head -10 >> "$REPORT_FILE"
    else
        echo "‚ö†Ô∏è  Top 10 non disponible" >> "$REPORT_FILE"
    fi
    
    cat >> "$REPORT_FILE" << EOF

================================================================================
5. STRUCTURE DES FICHIERS G√âN√âR√âS
================================================================================

R√©pertoire HDFS: $HDFS_OUTPUT/
  ‚îú‚îÄ‚îÄ clean/
  ‚îÇ   ‚îú‚îÄ‚îÄ v1/part-*           (R√©sultats nettoy√©s v1)
  ‚îÇ   ‚îú‚îÄ‚îÄ v2/part-*           (R√©sultats nettoy√©s v2)
  ‚îÇ   ‚îú‚îÄ‚îÄ combined.txt        (Tous les r√©sultats)
  ‚îÇ   ‚îî‚îÄ‚îÄ clean_only.txt      (Seulement les valides)
  ‚îú‚îÄ‚îÄ rejects/
  ‚îÇ   ‚îî‚îÄ‚îÄ rejected_lines.txt  (Lignes rejet√©es)
  ‚îú‚îÄ‚îÄ metrics/
  ‚îÇ   ‚îî‚îÄ‚îÄ part-*              (KPIs calcul√©s)
  ‚îî‚îÄ‚îÄ top10/
      ‚îî‚îÄ‚îÄ part-*              (Top produits)

R√©pertoire local: $LOCAL_OUTPUT/
  ‚îú‚îÄ‚îÄ clean/                  (Copies locales)
  ‚îú‚îÄ‚îÄ rejects/                (Erreurs)
  ‚îú‚îÄ‚îÄ metrics/
  ‚îÇ   ‚îú‚îÄ‚îÄ sales_by_country_month.jsonl
  ‚îÇ   ‚îî‚îÄ‚îÄ return_rate.jsonl
  ‚îú‚îÄ‚îÄ top10/
  ‚îÇ   ‚îî‚îÄ‚îÄ top10_products.txt
  ‚îî‚îÄ‚îÄ logs/
      ‚îú‚îÄ‚îÄ cleaning_v1.log
      ‚îú‚îÄ‚îÄ cleaning_v2.log
      ‚îú‚îÄ‚îÄ analysis.log
      ‚îî‚îÄ‚îÄ top10.log

================================================================================
6. JOBS MAPREDUCE EX√âCUT√âS
================================================================================

Historique des jobs YARN (10 derniers):
EOF
    
    yarn application -list -appStates ALL 2>&1 | tail -10 >> "$REPORT_FILE" || echo "YARN ResourceManager non disponible" >> "$REPORT_FILE"
    
    cat >> "$REPORT_FILE" << EOF

================================================================================
7. COMMANDES UTILES
================================================================================

Consulter les donn√©es HDFS:
  hdfs dfs -ls $HDFS_OUTPUT
  hdfs dfs -cat $HDFS_OUTPUT/clean/clean_only.txt | head -20

Consulter les logs:
  cat $LOCAL_OUTPUT/logs/*.log
  tail -f $LOCAL_OUTPUT/logs/cleaning_v1.log

R√©cup√©rer les r√©sultats sur votre Mac:
  docker cp hadoop_master:$LOCAL_OUTPUT ~/hadoop_results

Interfaces web:
  HDFS NameNode    : http://localhost:9870
  YARN ResourceMgr : http://localhost:8088
  JobHistory       : http://localhost:19888

================================================================================
8. R√âSUM√â EX√âCUTIF
================================================================================

‚úì Pipeline MapReduce ex√©cut√© avec succ√®s
‚úì $CLEAN enregistrements valides trait√©s sur $TOTAL ($SUCCESS_RATE%)
‚úì $REJECT enregistrements rejet√©s (erreurs de format/validation)
‚úì KPIs calcul√©s et disponibles dans: $LOCAL_OUTPUT/metrics/
‚úì Top 10 produits disponible dans: $LOCAL_OUTPUT/top10/

Performances du cluster:
  - Nombre de datanodes: 2 (worker-1, worker-2)
  - Jobs MapReduce: 3 (nettoyage, analyse, top10)
  - Temps d'ex√©cution: ~$(date '+%M') minutes (estimation)

================================================================================
FIN DU RAPPORT - $(date '+%Y-%m-%d %H:%M:%S')
================================================================================
EOF
    
    print_success "Rapport g√©n√©r√©: $REPORT_FILE"
    
    # Afficher un r√©sum√© console
    echo ""
    echo "‚ïî‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïó"
    echo "‚ïë                    R√âSUM√â DE L'EX√âCUTION                       ‚ïë"
    echo "‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù"
    echo ""
    echo "  üè¢ Cluster        : hadoop_master + worker-1 + worker-2"
    echo "  üìÅ HDFS           : $HDFS_OUTPUT"
    echo "  üìÅ Local          : $LOCAL_OUTPUT"
    echo "  ‚úì  Lignes trait√©es: $TOTAL"
    echo "  ‚úì  Lignes valides : $CLEAN ($SUCCESS_RATE%)"
    echo "  ‚ùå Lignes rejet√©es: $REJECT"
    echo "  üìä Rapport        : $REPORT_FILE"
    echo ""
}

# ============================================================================
# FONCTION PRINCIPALE
# ============================================================================

main() {
    echo ""
    echo "‚ïî‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïó"
    echo "‚ïë      PIPELINE MAPREDUCE - CLUSTER HADOOP DOCKER                ‚ïë"
    echo "‚ïë      Master: hadoop_master | Workers: worker-1, worker-2       ‚ïë"
    echo "‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù"
    echo ""
    
    # V√©rifications pr√©liminaires
    check_prerequisites
    check_hdfs_data
    clean_output
    
    echo ""
    echo "D√©marrage du pipeline MapReduce distribu√©..."
    echo ""
    
    # Ex√©cution des 3 √©tapes
    run_data_cleaning
    echo ""
    
    run_sales_analysis
    echo ""
    
    run_top_products
    echo ""
    
    # G√©n√©ration du rapport
    generate_report
    
    # Message de succ√®s final
    echo ""
    echo "‚ïî‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïó"
    echo "‚ïë                  ‚úì PIPELINE TERMIN√â AVEC SUCC√àS!               ‚ïë"
    echo "‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù"
    echo ""
    echo "Prochaines √©tapes:"
    echo "  1. Consulter le rapport:"
    echo "     cat $LOCAL_OUTPUT/RAPPORT_EXECUTION.txt"
    echo ""
    echo "  2. Voir les m√©triques:"
    echo "     cat $LOCAL_OUTPUT/metrics/return_rate.jsonl | python3 -m json.tool"
    echo "     cat $LOCAL_OUTPUT/top10/top10_products.txt"
    echo ""
    echo "  3. Voir les interfaces web:"
    echo "     - HDFS: http://localhost:9870"
    echo "     - YARN: http://localhost:8088"
    echo ""
    echo "  4. R√©cup√©rer les r√©sultats sur votre Mac:"
    echo "     docker cp hadoop_master:$LOCAL_OUTPUT ~/hadoop_results"
    echo ""
}

# Ex√©cuter le script principal
main